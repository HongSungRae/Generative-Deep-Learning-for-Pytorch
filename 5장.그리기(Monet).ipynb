{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 CycleGAN으로 모네 그림 그리기\n",
    "- 데이터셋을 [링크](https://www.kaggle.com/datasets/balraj98/monet2photo)\\[1]에서 다운 받은 뒤, 로컬에 ```./data/monet2photo``` 폴더를 만들어 넣어주세요.\n",
    "\n",
    "[1] Zhu et al., Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, ICCV 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "monet = os.listdir('./data/monet2photo/trainA/')[0:10]\n",
    "photo = os.listdir('./data/monet2photo/trainB/')[0:10]\n",
    "\n",
    "plt.figure(figsize=(40,10))\n",
    "for col, style in enumerate(['A','B']):\n",
    "    for row in range(10):\n",
    "        img_name = {\"A\":monet, \"B\":photo}[style][row]\n",
    "        img = plt.imread(f'./data/monet2photo/train{style}/{img_name}')/255\n",
    "        plt.subplot(2,10,col*10+row+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{style} : {img.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 생성자(ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_residuals=9):\n",
    "        super().__init__()\n",
    "        self.resize = transforms.Resize((256,256)) # 원래 사이즈로 안돼서 적용하겠습니다. 255 -> 256\n",
    "        residual = []\n",
    "        for _ in range(num_residuals):\n",
    "            residual.append(nn.Sequential(nn.Conv2d(128,128,3,1,1),\n",
    "                                          nn.InstanceNorm2d(128),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Conv2d(128,128,3,1,1),\n",
    "                                          nn.InstanceNorm2d(128)))\n",
    "        self.down = nn.Sequential(nn.Conv2d(3,32,7,1,1),\n",
    "                                  nn.InstanceNorm2d(32),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(32,64,3,2,1),\n",
    "                                  nn.InstanceNorm2d(64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(64,128,3,2,2),\n",
    "                                  nn.InstanceNorm2d(128),\n",
    "                                  nn.ReLU())\n",
    "        self.residual = nn.ModuleList(residual)\n",
    "        self.up = nn.Sequential(nn.ConvTranspose2d(128,64,3,2,2),\n",
    "                                nn.InstanceNorm2d(64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.ConvTranspose2d(64,32,3,2),\n",
    "                                nn.InstanceNorm2d(32),\n",
    "                                nn.ReLU(),\n",
    "                                nn.ConvTranspose2d(32,3,7,1,1),\n",
    "                                nn.InstanceNorm2d(3),\n",
    "                                nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.down(x)\n",
    "        for layer in self.residual:\n",
    "            residual = x.clone()\n",
    "            x = layer(x) + residual\n",
    "        x = self.up(x)\n",
    "        x = self.resize(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn((16,3,256,256))\n",
    "    model = ResNet()\n",
    "    y = model(x)\n",
    "    print(f'output shape : {y.shape}')\n",
    "    summary(model, (3,256,256), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Monet2Photo(Dataset):\n",
    "    def __init__(self, split):\n",
    "        assert split in ['train', 'test']\n",
    "        self.folder_name_monet = split + 'A'\n",
    "        self.folder_name_photo = split + 'B'\n",
    "        self.data_list_monet = os.listdir(f'./data/monet2photo/{self.folder_name_monet}')\n",
    "        self.data_list_photo = os.listdir(f'./data/monet2photo/{self.folder_name_photo}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return min(len(self.data_list_monet), len(self.data_list_photo))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Monet\n",
    "        img_monet = plt.imread(f'./data/monet2photo/{self.folder_name_monet}/{self.data_list_monet[idx]}')/255 # (256,256,3)\n",
    "        img_monet = np.einsum('...c->c...', img_monet)\n",
    "        img_monet = torch.from_numpy(img_monet)\n",
    "\n",
    "        # Photo\n",
    "        img_photo = plt.imread(f'./data/monet2photo/{self.folder_name_photo}/{self.data_list_photo[idx]}')/255 # (256,256,3)\n",
    "        img_photo = np.einsum('...c->c...', img_photo)\n",
    "        img_photo = torch.from_numpy(img_photo)\n",
    "        return img_monet.type(torch.float32), img_photo.type(torch.float32)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = Monet2Photo('train')\n",
    "    dataloader = DataLoader(dataset, 32)\n",
    "    img_monet, img_photo = next(iter(dataloader))\n",
    "    print(img_monet.shape, img_photo.shape)\n",
    "\n",
    "    del dataset, dataloader, img_monet, img_photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 학습(w.o identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter\n",
    "g_AB_lr = 2e-4\n",
    "g_BA_lr = 2e-4\n",
    "d_A_lr = 2e-4\n",
    "d_B_lr = 2e-4\n",
    "\n",
    "bs = 16 # batch size # 16GiB 단일 GPU에서 돌릴 수 있는 size. 여러분의 상황에 따라서 늘리거나 줄이세요\n",
    "epochs = 200\n",
    "g_d_ratio = 5 # D가 몇 번(g_d_ratio) 학습될 때 G가 한번 학습될지 정한다\n",
    "\n",
    "identity = False\n",
    "\n",
    "gpu = 1 # 여러분의 상황에 맞게 바꾸시길 바랍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "import torch.optim as optim\n",
    "\n",
    "g_AB = ResNet().cuda(gpu)\n",
    "g_BA = ResNet().cuda(gpu)\n",
    "\n",
    "d_A = PatchDiscriminator(in_channels=[3,16,32,16],\n",
    "                         out_channels=[16,32,16,3],\n",
    "                         kernel_size=[4,4,4,4],\n",
    "                         stride=[2,2,2,2],\n",
    "                         padding=[2,2,2,2]).cuda(gpu)\n",
    "\n",
    "d_B = PatchDiscriminator(in_channels=[3,16,32,16],\n",
    "                         out_channels=[16,32,16,3],\n",
    "                         kernel_size=[4,4,4,4],\n",
    "                         stride=[2,2,2,2],\n",
    "                         padding=[2,2,2,2]).cuda(gpu)\n",
    "\n",
    "# optimizer\n",
    "g_AB_optimizer = optim.Adam(g_AB.parameters(), lr=g_AB_lr)\n",
    "g_BA_optimizer = optim.Adam(g_BA.parameters(), lr=g_BA_lr)\n",
    "d_A_optimizer = optim.Adam(d_A.parameters(), lr=d_A_lr)\n",
    "d_B_optimizer = optim.Adam(d_B.parameters(), lr=d_B_lr)\n",
    "\n",
    "# criterion\n",
    "g_criterion = CycleGANGeneratorLoss(identity)\n",
    "d_criterion = CycleGANDiscrimonatorLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D -> G 순으로 학습하겠다\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dataset = Monet2Photo('train')\n",
    "test_dataset = Monet2Photo('test')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, bs, True)\n",
    "test_dataloader = DataLoader(test_dataset, bs, True)\n",
    "\n",
    "# 속도 향상\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 로그\n",
    "train_g_loss = []\n",
    "train_d_loss = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i, (img_monet, img_photo) in enumerate(train_dataloader):\n",
    "        # Discriminator 학습\n",
    "        img_monet, img_photo = img_monet.cuda(gpu), img_photo.cuda(gpu)\n",
    "\n",
    "        \n",
    "        fake_B = g_AB(img_monet)\n",
    "        fake_A = g_BA(img_photo)\n",
    "\n",
    "        pred_real_B = d_B(img_photo)\n",
    "        pred_fake_B = d_B(fake_B)\n",
    "        pred_real_A = d_A(img_monet)\n",
    "        pred_fake_A = d_A(fake_A)\n",
    "\n",
    "        d_loss = d_criterion(pred_real_A, pred_fake_A) + d_criterion(pred_real_B, pred_fake_B)\n",
    "        d_A_optimizer.zero_grad()\n",
    "        d_B_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_A_optimizer.step()\n",
    "        d_B_optimizer.step()\n",
    "        train_d_loss.append(d_loss.detach().cpu().item())\n",
    "\n",
    "        if (i+1)%g_d_ratio==0:\n",
    "            # Generator 학습\n",
    "            del fake_B, fake_A, pred_real_B, pred_fake_B, pred_real_A, pred_fake_A\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            img_monet = img_monet.detach().clone().cuda(gpu)\n",
    "            img_photo = img_photo.detach().clone().cuda(gpu)\n",
    "            img_monet.requires_grad, img_photo.requires_grad = True, True\n",
    "\n",
    "            \n",
    "            fake_B = g_AB(img_monet)\n",
    "            fake_A = g_BA(img_photo)\n",
    "            cycle_B = g_AB(fake_A) # B처럼 보여야한다\n",
    "            cycle_A = g_BA(fake_B) # A처럼 보여야한다\n",
    "            \n",
    "            pred_real_B = d_B(img_photo)\n",
    "            pred_fake_B = d_B(fake_B)\n",
    "            pred_real_A = d_A(img_monet)\n",
    "            pred_fake_A = d_A(fake_A)\n",
    "\n",
    "            if identity:\n",
    "                id_B = g_AB(img_photo) # orange 그대로 나와야한다\n",
    "                id_A = g_BA(img_monet) # apple 그대로 나와야한다\n",
    "            else:\n",
    "                id_B = None\n",
    "                id_A = None  \n",
    "\n",
    "            g_loss = g_criterion(img_monet,\n",
    "                                img_photo,\n",
    "                                pred_real_A,\n",
    "                                pred_real_B,\n",
    "                                pred_fake_A,\n",
    "                                pred_fake_B,\n",
    "                                cycle_A,\n",
    "                                cycle_B,\n",
    "                                id_A,\n",
    "                                id_B)\n",
    "            g_AB_optimizer.zero_grad()\n",
    "            g_BA_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_AB_optimizer.step()\n",
    "            g_BA_optimizer.step()\n",
    "            train_g_loss.append(g_loss.detach().cpu().item())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 학습결과 (w.o. identity)\n",
    "#### 5.2.5.1 Train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot([item for item in train_g_loss for _ in range(g_d_ratio)], label='Generator Loss') # g_d_ratio iter에 한 번만 학습했으므로 g_d_ratio회 복제해준다\n",
    "plt.plot(train_d_loss, label='Discriminator Loss')\n",
    "plt.xlabel('Iter')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5.2 Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet, photo = next(iter(test_dataloader))\n",
    "monet, photo = monet.cuda(gpu), photo.cuda(gpu)\n",
    "\n",
    "with torch.no_grad():\n",
    "    g_BA.eval()\n",
    "    g_AB.eval()\n",
    "    fake_photo = g_AB(monet)\n",
    "    fake_monet = g_BA(photo)\n",
    "    imgs_ = torch.cat([monet, fake_photo, photo, fake_monet],dim=0)\n",
    "    imgs = imgs_.detach().clone().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(60,20))\n",
    "for row in range(4):\n",
    "    name = {0:'Original monet', 1:'monet -> photo', 2:'Original photo', 3:'photo -> monet'}[row]\n",
    "    for col in range(1,bs+1):\n",
    "        img = imgs[row*bs+col-1]\n",
    "        img = np.einsum('c...->...c', img)\n",
    "        plt.subplot(4,bs,row*bs+col)\n",
    "        plt.imshow(img)\n",
    "        plt.title(name)\n",
    "\n",
    "del imgs_, imgs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5.3 Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    g_BA.eval()\n",
    "    g_AB.eval()\n",
    "    cycle_monet = g_BA(fake_photo)\n",
    "    cycle_photo = g_AB(fake_monet)\n",
    "    imgs = torch.cat([monet, cycle_monet, photo, cycle_photo],dim=0)\n",
    "    imgs = imgs.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(60,20))\n",
    "for row in range(4):\n",
    "    name = {0:'monet',1:'Recon monet', 2:'photo',3:'Recon photo'}[row]\n",
    "    for col in range(1,bs+1):\n",
    "        img = imgs[row*bs+col-1]\n",
    "        img = np.einsum('c...->...c', img)\n",
    "        plt.subplot(4,bs,row*bs+col)\n",
    "        plt.imshow(img)\n",
    "        plt.title(name)\n",
    "\n",
    "del cycle_monet, cycle_photo, imgs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5.4 identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    g_BA.eval()\n",
    "    g_AB.eval()\n",
    "    id_monet = g_BA(monet)\n",
    "    id_photo = g_AB(photo)\n",
    "    imgs = torch.cat([monet, id_monet, photo, id_photo],dim=0)\n",
    "    imgs = imgs.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(60,20))\n",
    "for row in range(4):\n",
    "    name = {0:'monet',1:'id monet', 2:'photo',3:'id photo'}[row]\n",
    "    for col in range(1,bs+1):\n",
    "        img = imgs[row*bs+col-1]\n",
    "        img = np.einsum('c...->...c', img)\n",
    "        plt.subplot(4,bs,row*bs+col)\n",
    "        plt.imshow(img)\n",
    "        plt.title(name)\n",
    "\n",
    "del id_monet, id_photo, imgs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.6 학습(w. identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.7 학습결과 (w. identity)\n",
    "#### 5.2.7.1 Train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.7.2 Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.7.3 Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.7.4 Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
